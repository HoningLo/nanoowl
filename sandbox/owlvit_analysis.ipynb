{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import PIL.Image\n",
    "import torch\n",
    "from transformers import (\n",
    "    OwlViTProcessor,\n",
    "    OwlViTForObjectDetection,\n",
    "    OwlViTVisionModel\n",
    ")\n",
    "from typing import Sequence, List, Tuple\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class OwlVit(object):\n",
    "    def __init__(self, threshold=0.1):\n",
    "        self.processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "        self.model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def predict(self, image: PIL.Image.Image, texts: Sequence[str]):\n",
    "        inputs = self.processor(text=texts, images=image, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        target_sizes = torch.Tensor([image.size[::-1]])\n",
    "        results = self.processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes, threshold=self.threshold)\n",
    "        i = 0\n",
    "        boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
    "        detections = []\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            detection = {\"bbox\": box.tolist(), \"score\": float(score), \"label\": int(label), \"text\": texts[label]}\n",
    "            detections.append(detection)\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "owlvit = OwlVit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleProfiler(object):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleRecorder(object):\n",
    "\n",
    "    def __init__(self, module: nn.Module):\n",
    "        self._module = module\n",
    "        self._input = None\n",
    "        self._output = None\n",
    "        self._hook = None\n",
    "\n",
    "    def _on_forward(self, module, input, output):\n",
    "        self._input = input\n",
    "        self._output = output\n",
    "\n",
    "    def attach(self):\n",
    "        if self._hook is not None:\n",
    "            raise RuntimeError(\"Hook already attached.\")\n",
    "        self._hook = self._module.register_forward_hook(self._on_forward)\n",
    "\n",
    "    def detach(self):\n",
    "        if self._hook is not None:\n",
    "            self._hook.remove()\n",
    "            self._hook = None\n",
    "\n",
    "    def __enter__(self, *args, **kwargs):\n",
    "        self.attach()\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.detach()\n",
    "\n",
    "    def get_input(self):\n",
    "        return self._input\n",
    "    \n",
    "    def get_output(self):\n",
    "        return self._output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(\"../assets/dogs.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_recorder = ModuleRecorder(owlvit.model.owlvit.vision_model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owlvit.model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_recorder.attach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = owlvit.predict(image, texts=[\"A dog\", \"A cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.708129982561073\n"
     ]
    }
   ],
   "source": [
    "count = 10\n",
    "t0 = time.perf_counter_ns()\n",
    "\n",
    "for i in range(count):\n",
    "    # out = owlvit.predict(image, texts=[\"A dog\", \"A cat\"])\n",
    "    owlvit.model.owlvit.vision_model(torch.randn(1, 3, 768, 768))\n",
    "torch.cuda.current_stream().synchronize()\n",
    "t1 = time.perf_counter_ns()\n",
    "dt = (t1 - t0) / 1e9\n",
    "print(count / dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 24*24*3*768*32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ((768//2)**2)*3*64*3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.333333333333333"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 577, 768])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_recorder.get_output().last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(768//32)**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method register_forward_hook in module torch.nn.modules.module:\n",
      "\n",
      "register_forward_hook(hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle method of transformers.models.owlvit.modeling_owlvit.OwlViTVisionTransformer instance\n",
      "    Registers a forward hook on the module.\n",
      "    \n",
      "    The hook will be called every time after :func:`forward` has computed an output.\n",
      "    It should have the following signature::\n",
      "    \n",
      "        hook(module, input, output) -> None or modified output\n",
      "    \n",
      "    The input contains only the positional arguments given to the module.\n",
      "    Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "    The hook can modify the output. It can modify the input inplace but\n",
      "    it will not have effect on forward since this is called after\n",
      "    :func:`forward` is called.\n",
      "    \n",
      "    Returns:\n",
      "        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "            a handle that can be used to remove the added hook by calling\n",
      "            ``handle.remove()``\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(owlvit.model.owlvit.vision_model.register_forward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 20.6480, -13.1593,   9.6784,  ..., -20.6196,  15.2642,  18.7416],\n",
       "         [ -1.3909,   1.0352,   0.3451,  ...,  -0.1778,   0.2200,   0.7068],\n",
       "         [ -0.3303,   1.6497,  -0.3364,  ...,  -0.5335,   0.3259,   1.2121],\n",
       "         ...,\n",
       "         [  1.0217,   2.0309,   0.1072,  ...,  -0.7548,   0.8171,   2.2222],\n",
       "         [  1.1874,   1.4332,  -0.7798,  ...,   0.0555,  -0.2738,   1.0362],\n",
       "         [  1.0650,  -1.1717,  -2.4873,  ...,  -0.5335,   0.9282,  -0.1461]]],\n",
       "       grad_fn=<AddBackward0>), pooler_output=tensor([[ 1.3095e+00, -1.0579e+00,  6.8421e-01, -5.0445e-01, -5.7594e-01,\n",
       "          1.0334e+00,  1.2500e+00,  1.0735e+00, -1.3173e+00,  1.9208e+00,\n",
       "         -1.4657e+00, -9.8172e-01,  1.2634e+00,  1.2387e+00,  1.0493e+00,\n",
       "          3.2842e-01, -1.4635e+00,  8.4521e-01,  1.3846e+00,  9.9562e-01,\n",
       "          6.1305e-01,  3.5310e-01,  1.1976e+00,  1.1578e+00,  2.5607e-01,\n",
       "          1.0382e+00,  1.1112e+00,  9.9394e-01, -9.6237e-01,  1.1569e+00,\n",
       "          3.7697e-01, -6.1954e-01, -8.0079e-01, -1.1434e+00, -6.1734e-01,\n",
       "          9.0199e-01, -4.1193e-01, -1.3652e+00,  9.0865e-01, -2.5015e-01,\n",
       "         -6.7124e-01, -7.4503e-01, -2.1563e-01,  7.8472e-02,  9.9217e-01,\n",
       "          7.9196e-01,  6.5351e-01,  1.2508e+00,  8.1036e-01,  1.6667e-01,\n",
       "         -1.4396e+00,  4.3539e-01,  9.7643e-01, -1.3784e+00, -1.7206e+00,\n",
       "         -5.2166e-01,  1.0848e+00, -9.7691e-01, -5.6041e-01, -5.0540e-01,\n",
       "          1.0191e+00, -7.2560e-01,  1.0139e+00, -7.1748e-01,  1.1642e+00,\n",
       "         -5.6036e-02, -1.8553e+00,  3.8623e-02,  1.1624e+00,  6.6073e-01,\n",
       "         -1.0008e+00,  7.5772e-01,  1.2747e+00,  9.6314e-01,  1.3306e+00,\n",
       "          9.7099e-01,  5.8415e-01,  8.7934e-01, -5.3378e-01,  4.7317e-01,\n",
       "          7.4114e-01,  2.8309e-01,  9.6057e-01,  9.3306e-02, -3.4241e-02,\n",
       "         -5.0725e-01, -1.2554e+00, -1.0366e+00,  8.1233e-01,  1.0647e+00,\n",
       "          9.7843e-01,  1.1713e+00, -6.2863e-01,  1.5325e-01, -4.5299e-01,\n",
       "          7.5260e-01,  1.1793e+00,  1.2342e+00,  7.8571e-01, -1.6468e+00,\n",
       "          9.3725e-01,  1.1669e+00, -1.0599e+00,  1.4729e-01,  6.0913e-01,\n",
       "          1.0820e+00,  9.3935e-01,  4.3509e-01, -2.8931e-01,  5.4159e-01,\n",
       "         -9.8401e-01,  1.2133e+00, -6.3618e-01, -2.8464e-01, -4.3541e-01,\n",
       "         -2.2859e-02,  2.4155e+00, -6.2337e-01,  9.9771e-01, -1.2277e+00,\n",
       "         -1.1069e+00,  1.3359e+00, -1.6226e-01,  1.1799e+00, -6.2198e-01,\n",
       "         -1.1509e+00, -6.6717e-01, -1.0094e+00, -1.1883e+00,  1.0605e+00,\n",
       "          1.3108e+00,  6.8903e-01,  1.4597e+00, -5.6984e-01, -1.1563e+00,\n",
       "         -1.3953e+00, -5.9876e-01, -1.3371e-01, -1.1477e+00, -1.0788e+00,\n",
       "          1.0290e+00, -4.3716e-01,  5.9602e-01,  8.0944e-01,  9.0840e-01,\n",
       "         -4.5875e-01,  9.4674e-01, -7.5518e-01, -8.5593e-01, -1.0276e+00,\n",
       "         -7.7136e-01, -9.9818e-01, -1.3277e+00,  5.4759e-01, -2.4782e-01,\n",
       "          7.4044e-01,  1.1786e+00,  1.1362e+00,  1.1557e+00, -1.1424e+00,\n",
       "          1.1194e+00,  7.5376e-01,  1.0416e+00,  1.0832e+00,  1.1003e+00,\n",
       "          6.7865e-01,  6.0477e-01,  1.7643e-01, -7.7373e-01, -1.2536e+00,\n",
       "         -4.7279e-01, -1.3795e+00,  1.2600e+00, -6.3634e-01,  1.3124e+00,\n",
       "          8.6926e-01,  9.6211e-01, -5.3736e-01, -1.2635e+00,  1.6485e+00,\n",
       "          1.0318e+00,  1.3392e+00,  1.2971e+00, -9.9939e-01,  1.0238e+00,\n",
       "          9.0818e-01, -8.5726e-01, -1.2723e+00,  1.1866e+00, -9.9765e-01,\n",
       "          1.1576e+00, -1.3052e+00,  6.2097e-01,  1.1766e+00,  1.0777e-01,\n",
       "          1.2833e+00, -1.0301e+00,  1.1510e+00, -1.7282e-01, -1.4212e+00,\n",
       "         -9.3524e-01,  1.0571e+00, -5.7852e-01,  1.1645e+00, -1.7358e-01,\n",
       "         -1.2977e+00, -3.3814e-01,  1.2375e-01, -1.1436e+00, -1.2077e+00,\n",
       "          9.1640e-01, -1.1968e+00,  1.7363e+00,  1.3313e+00,  1.3485e+00,\n",
       "          1.1837e+00,  1.9584e+00,  7.9744e-01,  2.7845e-01,  1.2829e+00,\n",
       "          1.2510e+00, -1.2528e+00, -6.2392e-02,  9.3118e-01, -4.0298e-01,\n",
       "          1.1589e+00,  4.9432e-01,  7.8567e-01, -8.9530e-01,  7.2053e-01,\n",
       "          9.6877e-01, -1.0468e+00,  1.2960e+00, -1.2696e+00, -1.2273e+00,\n",
       "          2.9625e-01, -6.2990e-01, -2.0691e-01,  1.8895e-02,  1.0637e+00,\n",
       "         -9.6402e-01,  3.5978e-01,  7.2410e-02,  9.5051e-01, -1.3643e+00,\n",
       "         -9.1283e-01,  4.5262e-01, -2.2296e-01,  1.0298e+00, -1.6515e+00,\n",
       "          1.1468e+00, -3.6818e-01, -1.2837e+00,  4.7838e-01, -1.3998e+00,\n",
       "         -6.4986e-01,  2.4404e-01,  1.6067e+00,  1.0266e+00,  1.3889e+00,\n",
       "          1.2895e+00, -7.3680e-01,  8.1656e-01,  1.1219e+00, -1.1756e+00,\n",
       "          1.0494e+00, -1.1246e+00, -5.5186e-01,  7.9559e-01, -1.1910e+00,\n",
       "          1.2225e+00,  7.4640e-01,  6.6189e-01, -7.9423e-01,  8.2122e-01,\n",
       "         -4.6632e-01,  6.7245e-01, -2.2342e-01,  8.5963e-01, -1.2415e+00,\n",
       "          7.8768e-01,  7.9501e-01, -1.2293e+00,  5.6145e-01, -2.5781e-01,\n",
       "          1.4856e+00, -1.2253e-01, -1.2370e+00, -9.3737e-01,  1.1366e+00,\n",
       "          1.1543e+00,  1.2096e+00, -1.1067e+00, -4.0780e-01,  4.3143e-01,\n",
       "         -9.1552e-01, -2.7449e-01,  7.5843e-01,  8.8360e-01,  1.1846e+00,\n",
       "         -1.2666e+00,  7.5741e-01, -1.2874e+00,  7.0397e-01, -1.3061e+00,\n",
       "          3.6663e-01, -2.9971e-01,  9.8513e-01,  5.6360e-01,  5.9891e+00,\n",
       "          6.7835e-01, -1.1511e+00, -6.1466e-01, -5.7969e-01, -3.5456e-01,\n",
       "         -6.4275e-01,  1.0062e-01, -4.8413e-02,  1.5138e+00,  1.0155e+00,\n",
       "          1.6219e+00, -1.0822e+00, -9.7815e-01,  1.2680e+00, -1.4888e+00,\n",
       "         -3.2627e-01, -1.1160e+00,  6.5097e-01,  5.9606e-01,  1.2121e+00,\n",
       "          1.2273e+00,  7.4589e-01, -1.1130e+00,  1.2430e+00,  1.2447e+00,\n",
       "         -1.0438e+00, -7.0215e-01,  1.0138e+00,  9.4853e-01, -1.1697e+00,\n",
       "         -1.0861e+00, -6.7286e-01, -1.2303e+00,  8.7317e-01,  1.2682e-01,\n",
       "         -9.6459e-01, -4.6767e-01,  1.0799e+00, -5.7157e-01,  2.3785e-01,\n",
       "          1.1115e+00,  1.8022e-01,  6.1631e-01, -4.4530e-01,  1.3211e+00,\n",
       "         -3.4460e-02,  1.1739e+00, -9.6748e-01,  1.3357e+00,  1.2460e+00,\n",
       "          7.6456e-01,  1.0137e+00, -5.7367e-01, -1.2383e+00,  6.2924e-01,\n",
       "         -1.2336e+00, -1.2596e+00,  7.2400e-01, -1.1717e+00,  9.7571e-01,\n",
       "          1.1314e+00, -1.2676e+00,  9.9062e-01, -6.9224e-01, -1.1118e+00,\n",
       "          3.6241e-01,  1.0681e+00,  9.2170e-01, -9.4729e-01,  6.0226e-01,\n",
       "         -8.1088e-01,  7.4864e-01,  9.1435e-01, -1.4208e-01,  1.3611e-01,\n",
       "         -1.4469e+00,  1.1892e+00, -1.1560e+00, -2.0106e-01,  9.4572e-01,\n",
       "          9.2417e-01,  4.7208e-01,  1.2200e+00, -1.3093e+00,  1.2481e+00,\n",
       "          1.2946e+00, -8.3685e-01,  1.1281e+00,  1.0554e+00,  8.4742e-01,\n",
       "         -1.2805e+00, -1.0811e+00,  1.1202e+00,  1.3026e+00,  1.3556e+00,\n",
       "          1.4133e+00,  8.6293e-01, -1.2375e+00,  1.1190e+00,  7.5901e-01,\n",
       "         -1.2412e+00,  6.5719e-01, -7.9116e-01,  5.2653e-03,  9.7651e-01,\n",
       "         -4.0431e-01,  1.2100e+00,  1.3529e+00,  1.3755e+00,  1.0925e+00,\n",
       "         -3.7781e-01,  1.2686e+00, -1.1844e+00, -1.1340e+00,  1.6170e+00,\n",
       "         -1.6190e-01, -8.7017e-02, -3.1847e-01,  5.3040e-01,  5.9605e-01,\n",
       "          1.2283e+00,  1.0091e+00,  5.9258e-01,  1.1379e+00,  8.9935e-01,\n",
       "         -8.4308e-01,  1.0985e+00,  1.4204e+00,  1.0968e+00, -2.7050e-01,\n",
       "         -1.4429e+00, -1.0970e+00,  7.7903e-01,  1.1581e+00, -1.3407e+00,\n",
       "         -1.0795e+00, -1.0332e+00,  9.3777e-01,  1.1504e+00,  1.0503e+00,\n",
       "          6.1967e-01, -1.4345e+00,  8.2675e-01,  1.0826e+00,  1.2122e+00,\n",
       "         -1.0044e+00, -6.2658e-02, -1.0557e+00, -4.9744e-01,  8.7774e-01,\n",
       "          8.3461e-01,  1.2994e+00, -4.7509e-01,  7.7109e-01, -1.1541e+00,\n",
       "          1.2341e+00,  1.0501e+00, -1.2385e+00,  1.0482e+00, -1.2171e+00,\n",
       "          9.2636e-01,  1.4463e+00,  1.0559e+00, -6.8262e-01,  1.2368e+00,\n",
       "         -6.8906e-01, -4.7344e-01,  1.1510e+00,  7.7499e-01,  1.0251e+00,\n",
       "          1.3226e+00,  1.0618e+00, -9.9637e-01,  1.2420e+00,  1.1222e+00,\n",
       "          1.1935e+00, -5.7117e-01,  9.0792e-01, -1.2076e+00,  9.4145e-01,\n",
       "          1.0474e+00,  1.2059e+00,  1.2776e+00, -4.7796e-01,  1.1047e+00,\n",
       "          7.1842e-01, -9.1694e-01, -8.9201e-01,  6.5449e-01,  1.1341e+00,\n",
       "          3.3260e-01,  3.7469e-01, -1.2146e+00, -1.1769e+00, -7.3991e-01,\n",
       "          1.4063e+00,  8.2161e-01,  1.0718e+00,  1.2919e+00,  8.3112e-01,\n",
       "         -1.1781e+00, -1.0676e+00,  7.5522e-01, -2.8292e-01,  1.0963e+00,\n",
       "          9.4134e-01,  6.7022e-01,  1.2335e+00,  9.1987e-01,  7.7060e-01,\n",
       "         -5.7096e-01, -1.1058e+00,  7.6066e-01,  1.1107e+00, -6.3133e-01,\n",
       "          9.9166e-01,  1.3187e+00, -4.0089e-02, -9.0842e-01,  1.2680e+00,\n",
       "          7.6395e-01,  5.1876e-01,  3.3623e-01,  9.1905e-01, -4.3332e-01,\n",
       "         -3.8415e-01,  1.1591e+00, -1.0054e+00,  1.1100e+00,  8.2893e-01,\n",
       "          8.2405e-01,  9.8623e-01, -3.3347e-01,  1.9096e-01,  1.0633e+00,\n",
       "          1.3447e+00, -1.1164e+00,  9.0475e-01,  1.2250e+00,  1.2832e+00,\n",
       "         -2.6512e-01, -1.0143e-01, -6.5203e-01,  1.1771e+00, -1.3097e+00,\n",
       "          9.1952e-01, -3.4732e-02,  1.9587e+00,  1.2985e+00,  1.1502e+00,\n",
       "          8.3799e-01,  7.6384e-01, -9.0004e-01,  1.0368e+00,  9.9950e-01,\n",
       "          4.5760e-01,  1.5041e+00, -1.1859e+00,  1.6037e-01, -2.6585e-01,\n",
       "          1.8911e-02, -2.2968e-01, -1.1734e+00,  8.9984e-01,  8.4873e-01,\n",
       "         -2.6297e-01,  1.7579e-01,  1.1960e+00,  2.8461e-01,  1.7788e+00,\n",
       "          9.3706e-01,  1.1787e+00,  8.3589e-01,  5.6108e-01, -2.8070e-01,\n",
       "         -7.2918e-02,  6.9915e-01,  9.4895e-01, -8.1939e-01,  7.2515e-01,\n",
       "          1.0445e+00,  1.7751e-01,  6.4766e-01, -8.2449e-01,  8.8658e-01,\n",
       "         -3.4687e-01,  3.9631e-01,  1.2022e+00, -1.1022e+00, -1.0774e+00,\n",
       "         -1.3242e+00, -1.0549e+00, -4.5119e-01,  1.1326e+00,  2.3746e+00,\n",
       "         -1.8247e+00,  7.1447e-01,  8.7518e-01, -1.1576e+00, -1.1450e+00,\n",
       "          1.2051e+00,  7.8763e-01,  6.0554e-01, -7.9515e-01,  1.1374e+00,\n",
       "          9.7573e-01, -1.7280e-01,  7.9976e-01,  1.1242e+00,  7.7015e-01,\n",
       "         -7.3938e-01,  1.3777e+00,  4.9632e-01,  6.8662e-01, -9.7760e-01,\n",
       "          4.6307e+00, -8.6114e-01, -1.1318e+00, -1.2457e+00, -9.6505e-01,\n",
       "          4.9852e-01, -9.9986e-01,  8.6548e-01,  7.3027e-01, -1.5868e+00,\n",
       "         -5.3371e-01,  8.9763e-01,  1.0132e+00,  1.1144e+00,  8.5599e-01,\n",
       "          8.4027e-01, -1.0831e-01,  1.3184e+00, -5.1533e-01, -1.2158e+00,\n",
       "         -5.6623e-01,  9.3304e-01, -1.2660e+00, -4.6633e-01, -8.4338e-01,\n",
       "          1.1929e+00,  9.4496e-01, -1.3219e+00, -8.9964e-01, -1.2514e+00,\n",
       "          1.1926e+00, -9.5631e-01,  9.9517e-01,  7.1461e-01, -3.6092e-01,\n",
       "          1.0173e+00, -6.7407e-01, -6.4297e-01, -1.1082e+00, -5.1696e-01,\n",
       "         -1.1157e+00,  5.6421e-01, -1.1147e+00, -2.9752e-01, -9.7814e-01,\n",
       "         -1.1691e+00, -7.4457e-01, -6.7750e-01, -1.0807e+00, -2.7652e-01,\n",
       "         -1.1149e+00,  4.4949e-01,  1.0025e+00, -9.0263e-01, -1.2173e+00,\n",
       "         -2.7588e-01, -1.2181e+00,  1.3386e+00, -1.1217e+00,  1.3134e+00,\n",
       "          4.6943e-01,  8.7091e-01,  8.6150e-01,  1.1068e+00,  1.4467e+00,\n",
       "         -7.1508e-01,  1.1616e+00, -1.1411e+00,  3.1833e-01, -1.1198e+00,\n",
       "          9.0502e-01,  1.0954e+00,  1.2403e+00, -6.3380e-01,  6.2756e-01,\n",
       "          1.0937e+00,  9.1407e-01,  3.2328e-01,  5.7344e-01,  1.1991e+00,\n",
       "         -9.4001e-01,  1.8358e+00,  8.4093e-01,  1.0406e+00, -1.2618e+00,\n",
       "          1.2918e+00, -1.4875e+00,  9.9099e-01,  9.2493e-01,  5.9219e-01,\n",
       "          8.1432e-01, -1.6481e+00, -1.1591e+00, -1.2634e+00, -1.5483e+00,\n",
       "          7.3109e-01,  7.6403e-01, -6.3650e-01,  1.2694e+00,  1.0798e+00,\n",
       "          7.6317e-01,  4.7969e-01,  2.9774e-01,  1.0230e+00, -1.0159e+00,\n",
       "          7.2096e-01,  5.4954e-01,  6.5985e-01,  6.9231e-01,  4.8736e-03,\n",
       "         -8.9089e-01, -4.8462e-01,  1.2045e+00,  1.1639e+00, -1.2934e+00,\n",
       "          1.1140e+00,  1.0495e+00,  1.0328e+00, -1.0223e+00,  1.2754e+00,\n",
       "         -1.1018e+00,  1.1163e+00, -3.8313e-01,  3.2151e-01,  1.1502e+00,\n",
       "          8.3092e-01, -1.4506e-01,  1.0592e+00,  1.3776e+00,  6.5294e-01,\n",
       "         -1.0490e+00,  4.9248e-01,  1.0738e+00,  1.2330e+00,  1.0565e+00,\n",
       "          1.0658e+00, -2.2881e-01, -1.5106e+00, -6.7746e-01,  7.2259e-01,\n",
       "         -1.1250e+00,  1.0731e+00,  1.3032e+00]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_recorder.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OwlViTProcessor:\n",
       "- image_processor: OwlViTImageProcessor {\n",
       "  \"crop_size\": {\n",
       "    \"height\": 768,\n",
       "    \"width\": 768\n",
       "  },\n",
       "  \"do_center_crop\": false,\n",
       "  \"do_convert_rgb\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"OwlViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.48145466,\n",
       "    0.4578275,\n",
       "    0.40821073\n",
       "  ],\n",
       "  \"image_processor_type\": \"OwlViTImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.26862954,\n",
       "    0.26130258,\n",
       "    0.27577711\n",
       "  ],\n",
       "  \"processor_class\": \"OwlViTProcessor\",\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 768,\n",
       "    \"width\": 768\n",
       "  }\n",
       "}\n",
       "\n",
       "- tokenizer: CLIPTokenizerFast(name_or_path='google/owlvit-base-patch32', vocab_size=49408, model_max_length=16, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '!'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owlvit.processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OwlViTVisionTransformer(\n",
       "  (embeddings): OwlViTVisionEmbeddings(\n",
       "    (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (position_embedding): Embedding(577, 768)\n",
       "  )\n",
       "  (pre_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (encoder): OwlViTEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): OwlViTEncoderLayer(\n",
       "        (self_attn): OwlViTAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): OwlViTMLP(\n",
       "          (activation_fn): QuickGELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owlvit.model.owlvit.vision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (1): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (2): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (3): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (4): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (5): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (6): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (7): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (8): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (9): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (10): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (11): OwlViTEncoderLayer(\n",
       "    (self_attn): OwlViTAttention(\n",
       "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): OwlViTMLP(\n",
       "      (activation_fn): QuickGELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owlvit.model.owlvit.vision_model.encoder.layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
